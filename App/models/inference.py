# -*- coding: utf-8 -*-
"""inference.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19HxR9D1i119bjHNP4Hgf1KNNkDyoovaD
"""

"""
Scanner Model Inference Module
- Loads hybrid CNN + tabular model
- Prepares fingerprint + FFT + LBP features
- Provides predict_from_bytes for app integration
"""

import io, pickle, joblib
import numpy as np
import tensorflow as tf
from pathlib import Path
from PIL import Image
from skimage.feature import local_binary_pattern
from app.utils.preprocess import preprocess_residual_from_array

# ----------------- BASE PATH -----------------
BASE = Path("app/models")

# ----------------- MODEL LOADER -----------------
def load_hybrid_model():
    """Load hybrid CNN+features model from available variants."""
    candidates = [
        BASE / "scanner_hybrid_14.keras",
        BASE / "scanner_hybrid.keras",
        BASE / "scanner_hybrid.h5"
    ]
    for p in candidates:
        if p.exists():
            return tf.keras.models.load_model(str(p))
    raise FileNotFoundError("No hybrid scanner model (.keras/.h5) found.")

hybrid_model = load_hybrid_model()
req_feat_dim = int(hybrid_model.inputs[1].shape[-1])

# ----------------- AUX DATA -----------------
scaler = joblib.load(BASE / "hybrid_feat_scaler.pkl")

if req_feat_dim == 30:
    fp_path, key_path = BASE/"scanner_fingerprints_14.pkl", BASE/"fp_keys_14.npy"
elif req_feat_dim == 27:
    fp_path, key_path = BASE/"scanner_fingerprints.pkl", BASE/"fp_keys.npy"
else:
    raise RuntimeError(f"Unsupported feature size: {req_feat_dim}")

with open(fp_path, "rb") as f:
    scanner_fps = pickle.load(f)
fp_keys = np.load(key_path, allow_pickle=True).tolist()

if getattr(scaler, "n_features_in_", None) != req_feat_dim:
    raise RuntimeError("Scaler features mismatch with model/tabular input")

label_enc = joblib.load(BASE / "hybrid_label_encoder.pkl")

# ----------------- FEATURE HELPERS -----------------
def corr2d(a: np.ndarray, b: np.ndarray) -> float:
    """Normalized correlation between 2 images."""
    a, b = a.astype(np.float32).ravel(), b.astype(np.float32).ravel()
    a -= a.mean(); b -= b.mean()
    denom = np.linalg.norm(a) * np.linalg.norm(b)
    return float((a @ b) / denom) if denom != 0 else 0.0

def fft_radial(img: np.ndarray, bins: int = 6):
    """Radial FFT energy distribution."""
    f = np.fft.fftshift(np.fft.fft2(img))
    mag = np.abs(f)
    h, w = mag.shape
    cy, cx = h // 2, w // 2
    yy, xx = np.ogrid[:h, :w]
    r = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)
    edges = np.linspace(0, r.max() + 1e-6, bins + 1)
    return [
        float(mag[(r >= edges[i]) & (r < edges[i+1])].mean()
              if np.any((r >= edges[i]) & (r < edges[i+1])) else 0.0)
        for i in range(bins)
    ]

def lbp_hist(img: np.ndarray, P: int = 8, R: float = 1.0):
    """Normalized LBP histogram."""
    rng = float(np.ptp(img))
    norm = np.zeros_like(img, dtype=np.float32) if rng < 1e-12 else (img - img.min()) / (rng + 1e-8)
    u8 = (norm * 255).astype(np.uint8)
    codes = local_binary_pattern(u8, P, R, method="uniform")
    n_bins = P + 2
    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)
    return hist.astype(np.float32).tolist()

def make_features(residual: np.ndarray):
    """Construct tabular features vector from residual fingerprint."""
    feats_corr = [corr2d(residual, scanner_fps[k]) for k in fp_keys]
    feats_fft  = fft_radial(residual, bins=6)
    feats_lbp  = lbp_hist(residual, P=8, R=1.0)
    vec = np.array(feats_corr + feats_fft + feats_lbp, dtype=np.float32).reshape(1, -1)
    return scaler.transform(vec)

# ----------------- PREDICT FUNCTION -----------------
def predict_from_bytes(img_bytes: bytes):
    """
    Run full inference pipeline.
    Args:
        img_bytes (bytes): input scanned page image
    Returns:
        dict: {label, confidence, top3}
    """
    # 1. Load + residual
    img = Image.open(io.BytesIO(img_bytes)).convert("L")
    res = preprocess_residual_from_array(np.array(img))

    # 2. Inputs
    x_img = np.expand_dims(res, axis=(0, -1))     # CNN branch
    x_tab = make_features(res)                    # Tabular branch

    # 3. Model predict
    probs = np.asarray(hybrid_model.predict([x_img, x_tab], verbose=0)).ravel()
    idx = int(np.argmax(probs))
    label = label_enc.classes_[idx]
    conf = float(probs[idx] * 100)

    # 4. Top-3
    k = min(3, probs.size)
    top_idx = np.argpartition(probs, -k)[-k:]
    top_idx = top_idx[np.argsort(probs[top_idx])[::-1]]
    top3 = [(label_enc.classes_[i], float(probs[i] * 100)) for i in top_idx]

    return {"label": label, "confidence": conf, "top3": top3}